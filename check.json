{'seed': 0, 'checkpoint_metric': 'val/loss/loss', 'log': {'wandb_entity': 'thomassutter', 'wandb_group': 'mv_wsl', 'wandb_run_name': '', 'wandb_project_name': 'mvvae', 'wandb_log_freq': 50, 'wandb_offline': False, 'wandb_local_instance': False, 'dir_logs': '/usr/scratch/projects/multimodality/mvvae/experiments', 'downstream_logging_frequency': 50, 'coherence_logging_frequency': 50, 'img_plotting_frequency': 50, 'fid_logging_frequency': 1, 'debug': False}, 


'dataset': {'name': 'CelebA', 'num_workers': 8, 'num_views': 2, 'dir_data_base': 'data/data', 'dir_alphabet': '', 'dir_clfs_base': 'data/trained_classifiers', 'dir_clfs': 'data/trained_classifiers/trained_clfs_celeba', 'len_sequence': 256, 'random_text_ordering': False, 'random_text_startindex': True, 'img_size': 64, 'image_channels': 3, 'crop_size_img': 148, 'n_clfs_outputs': 40, 'num_labels': 40, 'num_features': 41, 'num_layers_img': 5, 'filter_dim_img': 64, 'filter_dim_text': 64, 'beta_img': 1.0, 'beta_text': 1.0, 'skip_connections_img_weight_a': 1.0, 'skip_connections_img_weight_b': 1.0, 'skip_connections_text_weight_a': 1.0, 'skip_connections_text_weight_b': 1.0, 'use_rec_weight': True, 'include_channels_rec_weight': False}, 


'model': {'device': 'cuda', 'batch_size': 128, 'batch_size_eval': 64, 'lr': 0.0005, 'epochs': 500, 'latent_dim': 256, 'beta': 1.0, 'use_resnets': True, 'name': 'mixedprior', 'alpha_annealing': True, 'init_alpha_value': 1.0, 'final_alpha_value': 0.0, 'alpha_annealing_steps': 150000}, 'eval': {'num_samples_train': 10000, 'max_iteration': 10000, 'eval_downstream_task': True, 'coherence': True, 'path_inception_weights': 'data/trained_classifiers/pt_inception-2015-12-05-6726825d.pth'}}
